{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "import os\n",
    "\n",
    "# Move to parent directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from data.speeches import Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = Speeches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(speech_text: pd.Series):\n",
    "    all_models = {\n",
    "        'tfidf': TfidfVectorizer(max_features=1000, stop_words=\"english\", ngram_range=(1, 4)).fit(speech_text),\n",
    "        'word2vec': spacy.load('en_core_web_sm'),\n",
    "        'sentence2vec': SentenceTransformer('all-MiniLM-L6-v2'),\n",
    "        'instructor': INSTRUCTOR('hkunlp/instructor-base')\n",
    "    }\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "models = load_models(speeches.speeches_long['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_text = speeches.speeches_long['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_features(speech_text: pd.Series):\n",
    "    tfidf_features = models['tfidf'].transform(speech_text).toarray()\n",
    "    tfidf_features = pd.DataFrame(tfidf_features, columns=models['tfidf'].get_feature_names_out())\n",
    "    return tfidf_features\n",
    "\n",
    "def get_word2vec_features(speech_text: pd.Series):\n",
    "    word2vec_features = np.array([models['word2vec'](speech).vector for speech in speech_text])\n",
    "    print(word2vec_features.shape)\n",
    "    num_cols = word2vec_features.shape[1]\n",
    "    word2vec_features = pd.DataFrame(word2vec_features, columns=[f\"word2vec_{i}\" for i in range(num_cols)])\n",
    "    return word2vec_features\n",
    "\n",
    "def get_sentence2vec_features(speech_text: pd.Series):\n",
    "    sentence2vec_features = models['sentence2vec'].encode(speech_text)\n",
    "    num_cols = sentence2vec_features.shape[1]\n",
    "    sentence2vec_features = pd.DataFrame(sentence2vec_features, columns=[f\"sentence2vec_{i}\" for i in range(num_cols)])\n",
    "    return sentence2vec_features\n",
    "\n",
    "def get_instructor_features(speech_text: pd.Series):\n",
    "    instruction = \"Represent the presidential speech:\"\n",
    "    instructor_features = models['instructor'].encode([[instruction, x] for x in speech_text])\n",
    "    num_cols = instructor_features.shape[1]\n",
    "    instructor_features = pd.DataFrame(instructor_features, columns=[f\"instructor_{i}\" for i in range(num_cols)])\n",
    "    return instructor_features\n",
    "\n",
    "def get_features(speech_text, long=True, feature_type=\"tfidf\", **kwargs):\n",
    "    if feature_type == \"tfidf\":\n",
    "        features = get_tfidf_features(speech_text)\n",
    "    elif feature_type == \"word2vec\":\n",
    "        features = get_word2vec_features(speech_text)\n",
    "    elif feature_type == \"sentence2vec\":\n",
    "        features = get_sentence2vec_features(speech_text)\n",
    "    elif feature_type == \"instructor\":\n",
    "        features = get_instructor_features(speech_text)\n",
    "    else:\n",
    "        raise ValueError(\"feature_type must be one of tfidf, word2vec, sentence2vec, or instructor\")\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cason\\anaconda3\\envs\\presidential_env\\lib\\site-packages\\ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1756\\1470614404.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word2vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1756\\3382017694.py\u001b[0m in \u001b[0;36mget_features\u001b[1;34m(speech_text, long, feature_type, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tfidf_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mfeature_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"word2vec\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_word2vec_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mfeature_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"sentence2vec\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sentence2vec_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1756\\3382017694.py\u001b[0m in \u001b[0;36mget_word2vec_features\u001b[1;34m(speech_text)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mword2vec_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word2vec'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mspeech\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspeech_text\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2vec_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mnum_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mword2vec_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2vec_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"word2vec_{i}\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mword2vec_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "get_features(speech_text[:10], feature_type='word2vec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "presidential_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
